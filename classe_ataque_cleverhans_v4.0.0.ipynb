{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from cgi import test\n", "import json\n", "from easydict import EasyDict\n", "import joblib\n", "import os\n", "import importlib\n", "import sys\n", "import torch.optim as optim"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "import time\n", "import matplotlib.pyplot as plt\n", "import matplotlib.image as mpimg\n", "from typing import Union"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import torch\n", "from torchvision import datasets\n", "from torch.autograd import Variable\n", "import torch.nn.functional as F"]}, {"cell_type": "markdown", "metadata": {}, "source": ["CleverHans Lib v 4.0.0"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from cleverhans.utils import AccuracyReport\n", "from cleverhans.torch.attacks.fast_gradient_method import fast_gradient_method\n", "from cleverhans.torch.attacks.projected_gradient_descent import projected_gradient_descent\n", "from cleverhans.torch.attacks.carlini_wagner_l2 import carlini_wagner_l2\n", "from cleverhans.torch.attacks.sparse_l1_descent import sparse_l1_descent\n", "from cleverhans.torch.attacks.hop_skip_jump_attack import hop_skip_jump_attack\n", "from torch_ava.data.get_transformations import DataAugOperator\n", "from torch_ava.engine.evaluator import Evaluator\n", "from torch_ava.data import MedNISTDataset\n", "from torch_ava.data.gen_dataset_loader import LoaderOperator\n", "from torch_ava.engine.evaluator import Evaluator\n", "from torch_ava.torch_utils.operators import ModelOperator\n", "from models.Demo.torch_model import Network"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def set_module_import(model_name):\n", "    if \"ava_model\" in sys.modules.keys():\n", "        submodules = [mod for mod in sys.modules.keys() if mod.startswith(\"ava_model.\")]\n", "        del sys.modules[\"ava_model\"]\n", "        for submodule in submodules:\n", "            del sys.modules[submodule]\n", "    module_path = os.path.join(f\"./models/{model_name}\", \"__init__.py\")\n", "    module_path = os.path.abspath(module_path)\n", "    spec = importlib.util.spec_from_file_location(\"ava_model\", module_path)\n", "    module = importlib.util.module_from_spec(spec)\n", "    sys.modules[\"ava_model\"] = module\n", "    spec.loader.exec_module(module)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def get_configs(json_file_path: str) -> dict:\n", "    with open(json_file_path) as f:\n", "        json_confs = json.load(f)\n", "        return json_confs"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class Ataque:\n", "    def __init__(self):\n", "        self.model = model\n", "        self.path = path\n", "    def load_model(self, json_confs: dict):\n\n", "        # Loading the Epoch correctly\n", "        # Also this function is performing operations beyond the scope of its name. Maybe it could be better to\n", "        # separate them.\n", "        model = torch.load(self.path)\n", "        data_load = Ataque.load_dataset(json_confs)\n", "        print(\"Model successfully load!\")\n", "    def load_epoch(self, model):\n", "        x = LoaderOperator(torch_dset=path)\n", "        train_dl = x.get_loader(mode=train, torch_dset=path, batch_size=50)\n", "        test_dl = x.get_loader(mode=test, torch_dset=path, batch_size=50)\n", "        return train_dl, test_dl\n", "    def load_dataset(json_confs: dict, path_dataset: str = \"./MedNIST/\"):\n", "        # Dataset\n", "        # Load Data Transformation Pipelines\n", "        train_data_aug = DataAugOperator()\n", "        train_data_aug.set_pipeline(json_confs[\"train\"][\"transformations\"])\n", "        val_data_aug = DataAugOperator()\n", "        val_data_aug.set_pipeline(json_confs[\"val\"][\"transformations\"])\n", "        # Load Dataset\n", "        mednist_data = datasets.ImageFolder(root=path_dataset)\n", "        train_data = MedNISTDataset(mednist_data, train_data_aug.get_pipeline())\n", "        val_data = MedNISTDataset(mednist_data, val_data_aug.get_pipeline())\n", "        data_loader = LoaderOperator(train_data)\n", "        train_loader = data_loader.get_loader(\"train\", train_data, json_confs[\"train\"][\"batch_size\"])\n", "        val_loader = data_loader.get_loader(\"val\", val_data, json_confs[\"val\"][\"batch_size\"])\n", "        ch, w, h = train_data[0][0].shape\n", "        inpt_dims = [train_loader.batch_size, ch, w, h]\n", "        print(\"Input Dimensions:\", inpt_dims)\n", "        model = torch_model.Network(inpt_dims)\n", "        optimizer, scheduler = torch_model.get_optimizer(model)\n", "        print(model)\n\n", "        # TODO add the possibility to define which hardware will run the train\n", "        #Due to lack of hardware use_cuda must be False\n", "        model_operator = ModelOperator(torch_model.loss, optim, use_cuda=False)\n", "        model.to(model_operator.get_device())\n\n", "        # Train vanilla model\n", "        model.train()\n", "        for epoch in range(1, 1 + 1):\n", "            train_loss = 0.0\n", "            for x, y in train_loader:\n", "                x, y = x.to(model_operator.get_device()), y.to(model_operator.get_device())\n", "                optimizer.zero_grad()\n", "                out = model(x)\n", "                loss = model_operator.compute_loss(out, y)\n", "                loss.backward()\n", "                optimizer.step()\n", "                train_loss += loss.item()\n", "            print(\"epoch: {}/{}, train loss: {:.3f}\".format(epoch, 1, train_loss))\n\n", "        # Evaluate on clean and adversarial data\n\n", "        # Total eps of the adversarial attack\n", "        # TODO in the future we might want to explore this variable, thus we need to make it configurable\n", "        adva_eps = 0.3\n", "        model.eval()\n", "        report = EasyDict(nb_test=0, correct=0, correct_fgm=0, correct_pgd=0, correct_carliniwagnerl2=0, correct_sparse=0, correct_lbfgs=0, correct_hop=0)\n", "        for x, y in val_loader:\n", "            x, y = x.to(model_operator.get_device()), y.to(model_operator.get_device())\n", "            x_fgm = fast_gradient_method(model, x, adva_eps, np.inf)\n", "            #x_pgd = projected_gradient_descent(model, x, adva_eps, 0.01, 40, np.inf)\n", "            #x_sparse = sparse_l1_descent(model, x)\n", "            #x_carliniwagnerL2 = carlini_wagner_l2(model, x, n_classes=10)\n", "            #x_lbfgs = LBFGS(model)\n", "            x_hop = hop_skip_jump_attack(model, x, np.inf)\n", "            _, y_pred = model(x).max(1)  # model prediction on clean examples\n", "            _, y_pred_fgm = model(x_fgm).max(1)  # model prediction on FGM adversarial examples\n", "            #_, y_pred_pgd = model(x_pgd).max(1)  # model prediction on PGD adversarial examples\n", "            #_, y_pred_carliniwagnerl2 = model(x_carliniwagnerL2).max(1)\n", "            #_, y_pred_sparse = model(x_sparse).max(1) # model prediction on Sparse L1 Descent adversarial examples\n", "            #_, y_pred_lbfgs = model(x_lbfgs).max(1) # model prediction on LBFGS adversarial examples\n", "            _, y_pred_hop = model(x_hop).max(1) #model prediction on Hop Skip Jump adversarial examples\n", "            report.nb_test += y.size(0)\n", "            report.correct += y_pred.eq(y).sum().item()\n", "            #report.correct_fgm += y_pred_fgm.eq(y).sum().item()\n", "            #report.correct_pgd += y_pred_pgd.eq(y).sum().item()\n", "            #report.correct_carliniwagnerl2 += y_pred_carliniwagnerl2.eq(y).sum().item()\n", "            #report.correct_lbfgs += y_pred_lbfgs.eq(y).sum().item()\n", "            #report.correct_sparse += y_pred_sparse.eq(y).sum().item()\n", "            report.correct_hop += y_pred_hop.eq(y).sum().item()\n", "        print(\"test acc on clean examples (%): {:.3f}\".format(report.correct / report.nb_test * 100.0))\n", "        #print(\"test acc on FGM adversarial examples (%): {:.3f}\".format(report.correct_fgm / report.nb_test * 100.0))\n", "        #print(\"test acc on PGD adversarial examples (%): {:.3f}\".format(report.correct_pgd / report.nb_test * 100.0))\n", "        #print(\"test acc on Carlini Wagner L2 adversarial examples (%): {:.3f}\".format(report.correct_carliniwagnerl2 / report.nb_test * 100.0))\n", "        #print(\"test acc on Sparse L1 Descent adversarial examples (%): {:.3f}\".format(report.correct_sparse / report.nb_test * 100.0))\n", "        #print(\"test acc on LBFGS adversarial examples (%): {:.3f}\".format(report.correct_lbfgs / report.nb_test * 100.0))\n", "        print(\"test acc on Hop Skip Jump adversarial examples (%): {:.3f}\".format(report.correct_hop / report.nb_test * 100.0))"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}